# Breweries-Case
Breweries Case - BEES

## Setting up the Python Virtual Environment

1. Create the virtual environment:

    ```bash
    python -m venv venv
    ```

2. Activate the virtual environment:

    - **Linux/Mac**:
      ```bash
      source venv/bin/activate
      ```
    - **Windows**:
      ```bash
      .\venv\Scripts\activate
      ```


## Code Quality

This project uses [pre-commit](https://pre-commit.com/) and [flake8](https://flake8.pycqa.org/en/latest/) to enforce code standards.
1. **Instalar o pre-commit**: `pip install pre-commit`
2. **Instalar os hooks**: `pre-commit install`
3. **Rodar os hooks manualmente**: `pre-commit run --all-files`


# Infra - Buckets S3 do Projeto Breweries

Dentro da pasta Infra existe o Terraform que define os buckets S3 utilizados para o pipeline de dados do projeto.


## Requisitos

- Terraform >= 1.3
- AWS CLI configurado (com acesso √† conta que conter√° os buckets)

## Como usar

1. Inicialize o Terraform:
   ```bash
   terraform init
   terraform plan
   terraform apply

## Instru√ß√µes para rodar

### 1. Clone o reposit√≥rio

```bash
git https://github.com/MatheusZanchetta/Breweries-Case
cd Breweries-Case
```
### 2. Suba o docker
```
docker-compose build
docker-compose up
```
### 3. Logar no Airflow
Ap√≥s o docker estiver rodando, logar no Airflow http://localhost:8080/ e executar a DAG.



# üì¶ Buckets Criados

| Bucket Name                         | Finalidade                             | Camada    |
|------------------------------------|----------------------------------------|-----------|
| `mzan-raw-breweries-case`          | Armazena os dados brutos da API        | Bronze / RAW |
| `mzan-curated-breweries-case`      | Dados transformados em parquet             | Silver / Curated |
| `mzan-analytics-breweries-case`    | Dados agregados e prontos para consumo | Gold / Analytics |
| `airflow-breweries-logs`           | Armazena os logs do Airflow            | Logs       |

---

## üîÑ Fluxo dos Dados

A DAG √© configurada para rodar uma vez ao dia, as 12hrs. - **IMPORTANTE PARA O FUNCIONAMENTO DA L√ìGICA**
1. **Ingest√£o via API:**
   - A DAG "check_new_data" realiza chamadas para a [Open Brewery DB API](https://www.openbrewerydb.org/).
   - O job vinculado a essa DAG verifica se o bucket est√° vazio, se sim, realiza a carga completa, adicionado uma coluna com a data de execu√ß√£o.
   - Caso n√£o esteja vazio, ele cria um df com os ids dos dados e verifica com os ids do df criado pela api.
     - Se houver dados novos ele insere no bucket(adicionando a data de execu√ß√£o como uma coluna).
     - Se n√£o houver dados novos, ele sai do  DagFlow e termina a execu√ß√£o, sem passar pelas outras Tasks.
   - Os dados recebidos s√£o armazenados no bucket `mzan-raw-breweries-case` (camada RAW).

2. **Curated e Transforma√ß√£o:**
   - A task "curated_data" l√™ os arquivos RAW e salva esse df como parquet na zona curada.
   - Tamb√©m s√≥ insere dados novos, ele verifica se h√° dados com a data_execucao = a data de execucao do airflow, se sim, insere novos dados.
   - Os dados transformados s√£o gravados no bucket `mzan-curated-breweries-case`.

3. **Agrega√ß√µes e Enriquecimentos:**
   - Uma √∫ltima etapa agrega os dados (ex: n√∫mero de cervejarias por estado, tipos mais comuns, etc).
   - Tamb√©m s√≥ insere dados novos, ele verifica se h√° dados com a data_execucao = a data de execucao do airflow, se sim, insere novos dados.
   - Esses dados anal√≠ticos s√£o salvos em `mzan-analytics-breweries-case`.

---
## üîç Estrat√©gia de Monitoramento - Essa parte n√£o foi implementada

### 1. **Monitoramento de Falhas com Airflow Logs + SNS**

Todos os logs do Airflow s√£o armazenados no bucket S3 `airflow-breweries-logs`.

**Processo:**

1. Um DAG dedicado ou Lambda monitora periodicamente os logs recentes do Airflow nesse bucket.
2. Se uma falha for identificada (ex: presen√ßa de `"ERROR"` ou `Traceback` no log):
   - Um alerta √© enviado via **AWS SNS** para um grupo de e-mails t√©cnicos.
   - Uma notifica√ß√£o tamb√©m √© disparada para um canal no Slack espec√≠fico.
